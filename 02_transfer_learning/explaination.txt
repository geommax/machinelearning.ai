Transfer Learning အတွက် အရေးကြီးတာက Pretrained model တွေရဲ့ weight တွေ parameter တွေနဲ့  input parameters output parameter တွေသိဖို့အရေးကြီး
 image classification and object detection. တွေလုပ်ချင်တယ်ဆိုရင် ဒီ လို pretrained model တွေကို နားလည်မှ သက်သက်သာသာ train လို့ရမှာ ။ 

-------=-==========------------------------
လိုချင်တဲ့ class တွေထည့်မယ်၊ မလိုတာတွေကိုဖယ်မယ်၊ ဒါမျိုး တွေကိုစီစဥ်မှာ ။

ResNet50 model အတွက် တစ်ချက်ကြည့်ရအောင်၊ 

layer 50 နဲ့ဖွဲ့စည်းထား။ 

-------=-==========------------------------
Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

ပထမဆုံး layer မှာဆိုရင် input color 3 channel  input-img-size 224×224 out_channels=64 

the size of the filter (or kernel): a 7×7 square. broader အနားတွေ ရဲ့  patterns တွေကို စောစောစီးစီး feature ဆွဲထုတ်နိုင်ဖို့ဖြစ်ပါတယ်။

-------=-==========------------------------
output spatial size (height or width) of a convolution operation.
(224 - 7 + 2×3)/2 + 1 = 112

-------=-==========------------------------
output tensor shape က ဒါမျိုး ဖြစ်သွာပါမယ်။ 
[batch_size, 64, 112, 112]

-------=-==========------------------------

BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

Normalizes the 64 channels independently.

 converge faster and generalize better.
Affine=True means it has learnable parameters: gamma (scale) and beta (shift).
track_running_stats=True means it tracks running mean and variance during training.
----------------------------------------------------------------
ReLU(inplace=True) - ReLU(x) = max(0, x)
inplace=True means it modifies the data in-place to save memory.

----------------------------------------------------------------
MaxPool2d(kernel_size=3, stride=2, padding=1)

Performs downsampling by taking the maximum value in each 3×3 window.

Stride=2 → halves the width and height again.

Padding=1 → keeps spatial dimensions balanced.

Input shape: [B, 64, 112, 112] → Output shape: [B, 64, 56, 56]
----------------------------------------------------------------
----------------------------------------------------------------

The Bottleneck layer (or Bottleneck block) is a core building block of deep residual networks like ResNet-50 and deeper versions (ResNet-101, ResNet-152).
layer 1 sequential layer ကို bottleneck layer ဒါမှမဟုတ် block လို့လည်းခေါ်တယ်၊ ဒါမျိုး block တွေကို deep residual network တွေမှာ အများဆုံးတွေ့ရတယ်။ 
ဒီ layer ရဲ့ ရည်ရွယ်ချက်ကတော့ computation costs (တွက်ချက်မှုကုန်ကျစရိတ်) ကို လျှော့ချဖို့နဲ့ network ရဲ့ ထိရောက်မှုကို တိုးမြှင့်ဖို့ ဖြစ်ပါတယ်။
ပုံမှန် CNN model တွေကို အရှေ့မှာတုန်းက ကျွန်တော်တို့ ဆောက်ခဲ့ကြတယ်၊ 

CNN layers တွေများလာလေလေ ပိုရှုပ်ထွေးတဲ့ image တွေ complex features တွေပိုပြီး ကောင်းကောင်းဆွဲထုတ်လာနိုင်တယ်ဆိုပေမယ့်။ မူရင်း input image x တန်ဖိုးက ပျောက်သွားတက်ပါတယ်။ ဒါကို vanishing ဖြစ်တယ်လို့ခေါ်တယ်။ 
 performance က degrade ဖြစ်လာတက်တယ်။ ဆိုလိုတာက၊ gradient တွက်တဲ့အခါ loss, accuracy တွေ ကောင်းလာမလိုလိုနဲ့ training ,testing တွေပိုပြီးတိုးလာတယ်။ 

CNN layer တွေ များလာလေလေ၊ ပိုပြီးရှုပ်ထွေးတဲ့ feature တွေကို ထုတ်ယူနိုင်စွမ်းရှိလာမယ်လို့ ယူဆရပါတယ်။ ဒါပေမဲ့ လက်တွေ့မှာတော့ layer တွေ အရမ်းများလာတဲ့အခါ training error နဲ့ testing error တွေဟာ တိုးလာပြီး performance က ကျဆင်းလာပါတယ်။ ဒါကို degradation problem လို့ခေါ်ပါတယ်။ ဒီပြဿနာဟာ vanishing/exploding gradients တို့နဲ့လည်း ဆက်စပ်နေနိုင်ပါတယ်။

----------------------------------------------------------------
ResNet တွေဟာ ဒီ degradation problem ကို ဖြေရှင်းဖို့အတွက် residual connections (သို့မဟုတ် skip connections) ကို မိတ်ဆက်ခဲ့ပါတယ်။ ဒီ connections တွေဟာ input ကို layer အများကြီးထဲကနေ တိုက်ရိုက် output ကို ပြန်ပေါင်းထည့်ပေးတာပါ။

ဒါမျိုး model တစ်ခု ဖန်တီးဖို့ GPU firm တွေအများကြီး လိုတယ်၊ ကျွန်တော်ပိုင် တဲ့ dedicated 4 GB လောက်နဲ့မရဘူး ၊ အာ့ကြောင့် transfer learning ကိုပဲသုံးကြရတာ၊ 
ကိုယ်လိုချင်တဲ့ classfier ကို ပဲ train ပြီး class တစ်ခုအနေနဲ့ ထပ်ထည့်ကြရတယ်။ 

----------------------------------------------------------------
ဒီထဲမှာ feature map တွေကို input data အဖြစ်နဲ့ယူတယ် ပြီးရင် learn a non-linear transformation (the residual function)

ပုံမှန်အားဖြင့်၊ CNN layer တစ်ခုဟာ input x ကိုယူပြီး F(x) ဆိုတဲ့ transformation တစ်ခုကို လုပ်ဆောင်ပါတယ်။ ResNet မှာတော့ layer ဟာ F(x)+x ကို သင်ယူပါတယ်။ ဒီ x ကို တိုက်ရိုက်ဆက်သွယ်ထားတဲ့ လမ်းကြောင်းကို identity mapping လို့ခေါ်ပါတယ်။ ဒီလိုဆက်သွယ်မှုကြောင့်၊ layer ဟာ F(x) (residual function) ကိုပဲ သင်ယူဖို့ လိုအပ်ပါတယ်။ F(x) ကို သင်ယူဖို့က identity mapping x ကို သင်ယူတာထက် ပိုလွယ်ကူပြီး၊ gradient တွေကိုလည်း ပိုမိုထိရောက်စွာ ပြန်ဖြန့်နိုင်ပါတယ်။ ဒါကြောင့် layer တွေ ဘယ်လောက်နက်နက်ပဲဖြစ်ဖြစ်၊ အနည်းဆုံးတော့ identity mapping (input ကို တိုက်ရိုက်ပို့ပေးတာ) ကို သင်ယူနိုင်တဲ့အတွက် degradation မဖြစ်အောင် ကာကွယ်ပေးပါတယ်။

သေးငယ်တဲ့ dataset တွေနဲ့တောင် ကောင်းမွန်တဲ့ accuracy ကို ရရှိနိုင်ပါတယ်။

----------------------------------------------------------------

https://www.geeksforgeeks.org/deep-learning/residual-networks-resnet-deep-learning/

much deeper without forgetting input x 
---------------------------------------


Input (C channels) Input tensor shape: [B, 256, 56, 56] 
   |
[1x1 Conv] (reduce channels) 1×1 Conv	256 → 64 (Compression)
   |
[3x3 Conv]	3×3 Conv	64 → 64  (Spatial feature extraction)
   |
[1x1 Conv] (expand channels)	1×1 Conv	64 → 512 (Expansion)
   |
+----> Add input (1×1 Conv	256 → 512 ) The residual (skip) connection also downscales from 256 → 512 channels using downsample
   |
Output (C channels)

Residual Block ကို အသုံးပြုပြီးတော့ Google ImageNet, CoCo dataset တွေနဲ့ CIFR-10 တို့ မှာပါ စမ်းသပ်ခဲ့ပြီး 

----------------------------------------------------------------

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  ) 
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)