{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:12.066899Z",
     "iopub.status.busy": "2025-07-22T07:09:12.065359Z",
     "iopub.status.idle": "2025-07-22T07:09:12.074276Z",
     "shell.execute_reply": "2025-07-22T07:09:12.073132Z",
     "shell.execute_reply.started": "2025-07-22T07:09:12.066843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Link https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:12.077059Z",
     "iopub.status.busy": "2025-07-22T07:09:12.076695Z",
     "iopub.status.idle": "2025-07-22T07:09:12.104917Z",
     "shell.execute_reply": "2025-07-22T07:09:12.103753Z",
     "shell.execute_reply.started": "2025-07-22T07:09:12.077036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:12.106725Z",
     "iopub.status.busy": "2025-07-22T07:09:12.106357Z",
     "iopub.status.idle": "2025-07-22T07:09:12.127379Z",
     "shell.execute_reply": "2025-07-22T07:09:12.126044Z",
     "shell.execute_reply.started": "2025-07-22T07:09:12.106696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_path=r\"D:\\00_google_classroom\\machinelearning.ai\\02_transfer_learning\\images\\images\"\n",
    "train_dir=os.path.join(image_path,\"train\")\n",
    "test_dir=os.path.join(image_path,\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:12.128720Z",
     "iopub.status.busy": "2025-07-22T07:09:12.128446Z",
     "iopub.status.idle": "2025-07-22T07:09:14.780055Z",
     "shell.execute_reply": "2025-07-22T07:09:14.776355Z",
     "shell.execute_reply.started": "2025-07-22T07:09:12.128692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get list of classes and image paths\n",
    "classes = os.listdir(train_dir)\n",
    "all_images = []\n",
    "\n",
    "for cls in classes:\n",
    "    class_path = os.path.join(train_dir, cls)\n",
    "    images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "    all_images.extend(images)\n",
    "\n",
    "# Randomly select 25 images\n",
    "random_images = random.sample(all_images, 25)\n",
    "\n",
    "# Plot the 5x5 grid\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, img_path in enumerate(random_images):\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(os.path.basename(os.path.dirname(img_path)))  # show class label\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:14.786085Z",
     "iopub.status.busy": "2025-07-22T07:09:14.785608Z",
     "iopub.status.idle": "2025-07-22T07:09:16.808938Z",
     "shell.execute_reply": "2025-07-22T07:09:16.807607Z",
     "shell.execute_reply.started": "2025-07-22T07:09:14.786047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get list of classes and image paths\n",
    "classes = os.listdir(test_dir)\n",
    "all_images = []\n",
    "\n",
    "for cls in classes:\n",
    "    class_path = os.path.join(test_dir, cls)\n",
    "    images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "    all_images.extend(images)\n",
    "\n",
    "# Randomly select 25 images\n",
    "random_images = random.sample(all_images, 25)\n",
    "\n",
    "# Plot the 5x5 grid\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, img_path in enumerate(random_images):\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(os.path.basename(os.path.dirname(img_path)))  # show class label\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:17.082076Z",
     "iopub.status.busy": "2025-07-22T07:09:17.081683Z",
     "iopub.status.idle": "2025-07-22T07:09:17.347783Z",
     "shell.execute_reply": "2025-07-22T07:09:17.346706Z",
     "shell.execute_reply.started": "2025-07-22T07:09:17.082044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_counts = {}\n",
    "\n",
    "for class_name in os.listdir(test_dir):\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        count = len(os.listdir(class_path))\n",
    "        class_counts[class_name] = count\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Image Count'])\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(data=df_counts, x='Class', y='Image Count', palette='Dark2')\n",
    "plt.title(\"Number of Images per Class in Test Directory\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:17.349118Z",
     "iopub.status.busy": "2025-07-22T07:09:17.348786Z",
     "iopub.status.idle": "2025-07-22T07:09:17.771645Z",
     "shell.execute_reply": "2025-07-22T07:09:17.770503Z",
     "shell.execute_reply.started": "2025-07-22T07:09:17.349096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Lambda(lambda image: image.convert(\"RGB\")),  # always 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "image_path=Path(image_path)\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:17.772955Z",
     "iopub.status.busy": "2025-07-22T07:09:17.772700Z",
     "iopub.status.idle": "2025-07-22T07:09:18.818037Z",
     "shell.execute_reply": "2025-07-22T07:09:18.816931Z",
     "shell.execute_reply.started": "2025-07-22T07:09:17.772937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=5, seed=42):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            transformed_image = transform(f).permute(1, 2, 0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_path_list, transform=data_transform, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:09:18.819805Z",
     "iopub.status.busy": "2025-07-22T07:09:18.819450Z",
     "iopub.status.idle": "2025-07-22T07:10:54.364853Z",
     "shell.execute_reply": "2025-07-22T07:10:54.363807Z",
     "shell.execute_reply.started": "2025-07-22T07:09:18.819777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:10:54.366346Z",
     "iopub.status.busy": "2025-07-22T07:10:54.365995Z",
     "iopub.status.idle": "2025-07-22T07:10:54.373345Z",
     "shell.execute_reply": "2025-07-22T07:10:54.372227Z",
     "shell.execute_reply.started": "2025-07-22T07:10:54.366318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:10:54.374799Z",
     "iopub.status.busy": "2025-07-22T07:10:54.374491Z",
     "iopub.status.idle": "2025-07-22T07:10:54.397613Z",
     "shell.execute_reply": "2025-07-22T07:10:54.396577Z",
     "shell.execute_reply.started": "2025-07-22T07:10:54.374779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:10:54.399172Z",
     "iopub.status.busy": "2025-07-22T07:10:54.398764Z",
     "iopub.status.idle": "2025-07-22T07:10:54.417094Z",
     "shell.execute_reply": "2025-07-22T07:10:54.415977Z",
     "shell.execute_reply.started": "2025-07-22T07:10:54.399143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:10:54.421156Z",
     "iopub.status.busy": "2025-07-22T07:10:54.420785Z",
     "iopub.status.idle": "2025-07-22T07:10:54.482164Z",
     "shell.execute_reply": "2025-07-22T07:10:54.481189Z",
     "shell.execute_reply.started": "2025-07-22T07:10:54.421123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:10:54.483626Z",
     "iopub.status.busy": "2025-07-22T07:10:54.483367Z",
     "iopub.status.idle": "2025-07-22T07:10:54.492174Z",
     "shell.execute_reply": "2025-07-22T07:10:54.491179Z",
     "shell.execute_reply.started": "2025-07-22T07:10:54.483606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=8,  # how many samples per batch?\n",
    "    num_workers=0,  # how many subprocesses to use for data loading? (higher = more)\n",
    "    shuffle=True    # shuffle the data?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    shuffle=False   # don't usually need to shuffle testing data\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "feature_extractor.fc = nn.Identity()\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "def extract_features(dataset):\n",
    "    features = []\n",
    "    labels = []\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = feature_extractor(imgs)\n",
    "            features.append(feats.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_data)\n",
    "test_features, test_labels = extract_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='linear', probability=True)\n",
    "svm_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-22T07:11:26.895672Z",
     "iopub.status.idle": "2025-07-22T07:11:26.896077Z",
     "shell.execute_reply": "2025-07-22T07:11:26.895867Z",
     "shell.execute_reply.started": "2025-07-22T07:11:26.895849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_preds = svm_clf.predict(test_features)\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds, target_names=class_names))\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, feature_extractor, svm_clf, class_names):\n",
    "    image = Image.open(image_path)\n",
    "    image = data_transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feature = feature_extractor(image).cpu().numpy()\n",
    "    pred = svm_clf.predict(feature)[0]\n",
    "    prob = svm_clf.predict_proba(feature)[0][pred]\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(f\"Prediction: {class_names[pred]} ({prob*100:.2f}%)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return class_names[pred], prob\n",
    "\n",
    "sample_image_path = r\"D:\\00_google_classroom\\machinelearning.ai\\02_transfer_learning\\images\\images\\validation\\disgust\\1115.jpg\"\n",
    "predict_image(sample_image_path, feature_extractor, svm_clf, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, \"facial_expression_svm.joblib\")\n",
    "joblib.dump(svm_clf, save_path)\n",
    "print(f\"SVM model saved successfully in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 99505,
     "sourceId": 234911,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
