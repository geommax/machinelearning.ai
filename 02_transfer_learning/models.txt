| Framework              | Recommended Model(s)                                      | Reason                                |
| ---------------------- | --------------------------------------------------------- | ------------------------------------- |
| **PyTorch**            | `resnet18`, `resnet50`, `mobilenet_v2`, `efficientnet_b0` | Easy to use from `torchvision.models` |
| **TensorFlow / Keras** | `ResNet50`, `MobileNetV2`, `EfficientNetB0`, `VGG16`      | Built-in in `tf.keras.applications`   |

| Category    | Examples from ImageNet Classes (used in pretraining) |
| ----------- | ---------------------------------------------------- |
| üê∂ Animals  | German shepherd, tabby cat, Persian cat, lion, horse |
| üõ†Ô∏è Objects | Keyboard, pencil box, backpack, broom, computer      |
| üöó Vehicles | Firetruck, airplane, mountain bike, car, tank        |
| üß± Scenes   | Volcano, castle, church, stadium, seashore           |
| üçî Food     | Hotdog, cheeseburger, espresso, pizza, mushroom      |
| üëï Clothing | Kimono, lab coat, jeans, bathing suit                |

| Model           | Default Classes  | Source Dataset | Transferable To       |
| --------------- | ---------------- | -------------- | --------------------- |
| ResNet18/50     | 1,000 (ImageNet) | ImageNet       | Any image type        |
| MobileNetV2     | 1,000 (ImageNet) | ImageNet       | Mobile apps, IoT      |
| EfficientNet B0 | 1,000 (ImageNet) | ImageNet       | High-accuracy tasks   |
| VGG16/VGG19     | 1,000 (ImageNet) | ImageNet       | Easy-to-visualize     |
| InceptionV3     | 1,000 (ImageNet) | ImageNet       | Advanced architecture |

https://docs.pytorch.org/tutorials/
https://pytorch.org/hub/pytorch_vision_resnet/


Best by Difference Criteria
| Goal                                             | Best Model(s)                                                                       |
| ------------------------------------------------ | ----------------------------------------------------------------------------------- |
| ‚úÖ **Highest accuracy (ImageNet)**                | `ViT_H_14_Weights`, `Swin_V2_B_Weights`, `EfficientNet_B7_Weights`                  |
| ‚ö° **Fast inference (CPU/mobile)**                | `MobileNet_V3_Small_Weights`, `ShuffleNet_V2_X1_0_Weights`, `SqueezeNet1_1_Weights` |
| ‚öñÔ∏è **Best accuracy vs size trade-off**           | `EfficientNet_B0` to `B3`, `ResNet50_Weights`, `Swin_T_Weights`                     |
| üß† **Best for transfer learning**                | `ResNet50`, `EfficientNet_B0`, `ViT_B_16`                                           |
| üß™ **For research / custom fine-tuning**         | `VisionTransformer`, `SwinTransformer`, `MaxVit`, `ConvNeXt_B`                      |
| üßµ **Lightweight and small memory**              | `MobileNetV2`, `ShuffleNetV2`, `SqueezeNet`                                         |
| üì¶ **Classic architecture (easy to understand)** | `AlexNet`, `VGG16`, `ResNet18`                                                      |
| üõ†Ô∏è **Robust baseline**                          | `ResNet50`, `EfficientNet_B0`, `ViT_B_16`                                           |


Top Choice per Category 
| Category                         | Best Pick                                            |
| -------------------------------- | ---------------------------------------------------- |
| **Overall Best Accuracy**        | üß† `ViT_H_14_Weights` (requires a lot of GPU memory) |
| **Best All-Around**              | ‚öñÔ∏è `EfficientNet_B3` or `ResNet50_Weights`           |
| **Best Tiny Model**              | üì± `MobileNet_V3_Small_Weights`                      |
| **Best for Vision Transformers** | üß† `Swin_V2_B_Weights`                               |
| **Best for Quick Prototypes**    | ‚ö° `ResNet18_Weights` or `MobileNet_V2_Weights`       |

Recommendation based on use case
| Scenario                               | Recommended Model                           |
| -------------------------------------- | ------------------------------------------- |
| Mobile app or embedded                 | `MobileNetV3_Small`, `ShuffleNet_V2_X0_5`   |
| Academic / research / highest accuracy | `ViT_H_14`, `Swin_V2_B`, `EfficientNet_B7`  |
| Limited GPU (e.g., 8GB or less)        | `ResNet50`, `EfficientNet_B0`, `Swin_T`     |
| Speed-critical deployment              | `SqueezeNet1_1`, `MobileNetV3_Large`        |
| Studying CNN basics                    | `AlexNet`, `VGG16`, `ResNet18`              |
| Want flexibility + accuracy            | `SwinTransformer`, `ConvNeXt_S`, `ViT_B_16` |

Difference Between AlexNet and AlexNet_Weights

| Feature    | `AlexNet`                                       | `AlexNet_Weights`                                    |
| ---------- | ----------------------------------------------- | ---------------------------------------------------- |
| What it is | The model architecture                          | Enum that defines pretrained weights                 |
| Purpose    | Defines the CNN structure (layers, activations) | Provides pretrained parameters (trained on ImageNet) |
| Usage      | Used to create model                            | Used to specify which weights to load                |
| Example    | `model = alexnet()`                             | `weights = AlexNet_Weights.DEFAULT`                  |
Summary (AlexNet)
| Term                      | Purpose                                      |
| ------------------------- | -------------------------------------------- |
| `AlexNet`                 | Loads the model architecture                 |
| `AlexNet_Weights.DEFAULT` | Loads pretrained weights (e.g., on ImageNet) |

Difference Between Variants (ConvNeXt)
| Variant   | Parameters (approx.) | Accuracy (Top-1 on ImageNet)  | Use Case                             |
| --------- | -------------------- | ----------------------------  | ------------------------------------ |
| **Tiny**  | ~29M                 | ~82.1%                        | Lightweight tasks, mobile            |
| **Small** | ~50M                 | ~83.1%                        | Balanced speed and accuracy          |
| **Base**  | ~89M                 | ~83.8%                        | General use                          |
| **Large** | ~198M                | ~84.3%                        | High-accuracy tasks, more GPU needed |
Summary (ConvNeXt)
| Term                     | Type         | Description                        |
| ------------------------ | ------------ | ---------------------------------- |
| `ConvNeXt`               | Model        | General architecture name          |
| `ConvNeXt_Tiny_Weights`  | Weights Enum | Pretrained weights for Tiny model  |
| `ConvNeXt_Small_Weights` | Weights Enum | Pretrained weights for Small model |
| `ConvNeXt_Base_Weights`  | Weights Enum | Pretrained weights for Base model  |
| `ConvNeXt_Large_Weights` | Weights Enum | Pretrained weights for Large model |

Key Difference (DenseNet)
| Variant               | Depth      | Parameters | Accuracy (ImageNet Top-1) | Description                          |
| --------------------- | ---------- | ---------- | ------------------------- | ------------------------------------ |
| `DenseNet121_Weights` | 121 layers | ~8M        | ~74.4%                    | Light and fast                       |
| `DenseNet161_Weights` | 161 layers | ~29M       | ~77.1%                    | Much deeper and larger               |
| `DenseNet169_Weights` | 169 layers | ~14M       | ~75.6%                    | Balance of depth and size            |
| `DenseNet201_Weights` | 201 layers | ~20M       | ~76.9%                    | Deeper than 169 but lighter than 161 |
  
Summary Table(DenseNet)
| Term                  | Type         | Description                                      |
| --------------------- | ------------ | ------------------------------------------------ |
| `DenseNet`            | Model family | General CNN architecture using dense connections |
| `DenseNet121_Weights` | Weights enum | Pretrained model with 121 layers                 |
| `DenseNet161_Weights` | Weights enum | Pretrained model with 161 layers                 |
| `DenseNet169_Weights` | Weights enum | Pretrained model with 169 layers                 |
| `DenseNet201_Weights` | Weights enum | Pretrained model with 201 layers                 |

EfficientNet B0‚ÄìB7 Comparison
| Model | Parameters | Input Size | Top-1 Accuracy (ImageNet) | Use Case                  |
| ----- | ---------- | ---------- | ------------------------- | ------------------------- |
| B0    | ~5.3M      | 224√ó224    | ~77.1%                   | Very lightweight (mobile) |
| B1    | ~7.8M      | 240√ó240    | ~79.1%                   | Slightly better accuracy  |
| B2    | ~9.2M      | 260√ó260    | ~80.1%                   | Moderate                  |
| B3    | ~12M       | 300√ó300    | ~81.6%                   | Balance                   |
| B4    | ~19M       | 380√ó380    | ~83.0%                   | High-accuracy tasks       |
| B5    | ~30M       | 456√ó456    | ~83.6%                   | Needs strong GPU          |
| B6    | ~43M       | 528√ó528    | ~84.0%                   | Very high compute         |
| B7    | ~66M       | 600√ó600    | ~84.4%                   | Most accurate, slowest    |

EfficientNet V2 Variants
| Model    | Parameters | Input Size | Accuracy | Comment    |
| -------- | ---------- | ---------- | -------- | ---------- |
| V2-S     | ~22M       | 300√ó300    | ~83.9%  | Small (S)  |
| V2-M     | ~55M       | 384√ó384    | ~85.1%  | Medium (M) |
| V2-L     | ~120M      | 480√ó480    | ~85.7%  | Large (L)  |

Summary Table (Efficient Net)
| Term                        | Type         | Description                                       |
| --------------------------- | ------------ | ------------------------------------------------- |
| `EfficientNet`              | Model family | CNN designed for efficiency and scaling           |
| `EfficientNet_Bx_Weights`   | Weights enum | Pretrained weights for EfficientNet B0‚ÄìB7         |
| `EfficientNet_V2_X_Weights` | Weights enum | Weights for new V2 models (S/M/L), more efficient |

Summary Table (GoogleNet)
| Term                | Type        | Description                                                      |
| ------------------- | ----------- | ---------------------------------------------------------------- |
| `GoogLeNet`         | Model       | Inception v1 CNN model architecture                              |
| `GoogLeNet_Weights` | Enum        | Pretrained weights (e.g., ImageNet)                              |
| `GoogLeNetOutputs`  | Named Tuple | Output structure when using auxiliary classifiers (for training) |


Summary Table (Inception)
| Term                   | Type        | Description                                                     |
| ---------------------- | ----------- | --------------------------------------------------------------- |
| `Inception3`           | Model       | Inception v3 architecture (a.k.a. `inception_v3`)               |
| `Inception_V3_Weights` | Enum        | Pretrained weights (ImageNet-trained)                           |
| `InceptionOutputs`     | Named Tuple | Holds `logits` and `aux_logits` if auxiliary classifier is used |

Comparison: Inception v1 (GoogLeNet) vs v3
| Feature               | Inception v1 (GoogLeNet) | Inception v3       |
| --------------------- | ------------------------ | ------------------ |
| Parameters            | ~6.8M                  , | ~24M              |
| Input Size            | 224√ó224                  | 299√ó299            |
| Accuracy (Top-1)      | ~69.8%                   | ~78.8%            |
| Model Name in PyTorch | `googlenet`              | `inception_v3`     |
| Output Type           | `GoogLeNetOutputs`       | `InceptionOutputs` |

Comparison of MNASNet Variants
| Variant               | Width Multiplier | Parameters | Top-1 Accuracy (ImageNet) | Use Case                       |
| --------------------- | ---------------- | ---------- | ------------------------- | ------------------------------ |
| `MNASNet0_5_Weights`  | 0.5√ó             | ~2.2M      | ~65.4%                   | Very lightweight               |
| `MNASNet0_75_Weights` | 0.75√ó            | ~3.1M      | ~68.9%                   | Lightweight                    |
| `MNASNet1_0_Weights`  | 1.0√ó (default)   | ~4.4M      | ~73.5%                   | Balanced choice                |
| `MNASNet1_3_Weights`  | 1.3√ó             | ~7.9M      | ~75.2%                   | Highest accuracy, more compute |

Summary Table(MNASNet)
| Term                  | Type         | Description                        |
| --------------------- | ------------ | ---------------------------------- |
| `MNASNet`             | Model family | Mobile-first CNN designed via NAS  |
| `MNASNet0_5_Weights`  | Weights Enum | For 0.5√ó width (smallest, fastest) |
| `MNASNet0_75_Weights` | Weights Enum | 0.75√ó width                        |
| `MNASNet1_0_Weights`  | Weights Enum | 1.0√ó width (default)               |
| `MNASNet1_3_Weights`  | Weights Enum | 1.3√ó width (most accurate)         |

Summary (MaxVit)(Maximal Vision Transformer)
| Term               | Type           | Description                                             |
| ------------------ | -------------- | ------------------------------------------------------- |
| `MaxVit`           | Model family   | Vision model that fuses CNN + Axial + Block attention   |
| `maxvit_t`         | Specific Model | Tiny variant of MaxViT                                  |
| `MaxVit_T_Weights` | Enum           | Pretrained weights (usually on ImageNet) for `maxvit_t` |

Summary (MobileNet)
| Enum                         | Model                  | Description                   |
| ---------------------------- | ---------------------- | ----------------------------- |
| `MobileNet_V2_Weights`       | `mobilenet_v2()`       | Weights trained on ImageNet   |
| `MobileNet_V3_Large_Weights` | `mobilenet_v3_large()` | Weights for MobileNetV3-Large |
| `MobileNet_V3_Small_Weights` | `mobilenet_v3_small()` | Weights for MobileNetV3-Small |

Comparison Table
| Feature                    | MobileNetV2        | MobileNetV3-Large  | MobileNetV3-Small  |
| -------------------------- | ------------------ | ------------------ | ------------------ |
| Introduced                 | 2018               | 2019               | 2019               |
| Architecture               | Inverted residuals | NAS + SE + H-Swish | NAS + SE + H-Swish |
| Speed                      | Fast               | Fast               | Very fast          |
| Accuracy (Top-1, ImageNet) | ~71.8%             | ~75.2%             | ~67.4%            |
| Parameters                 | ~3.4M              | ~5.4M              | ~2.9M             |
| Use Case                   | General mobile     | High accuracy      | Low-latency apps   |

Summary (MobileNet)
| Term                         | Type         | Description                              |
| ---------------------------- | ------------ | ---------------------------------------- |
| `MobileNetV2`                | Model        | Lightweight CNN with inverted residuals  |
| `MobileNetV3`                | Model family | Improved version with NAS and SE         |
| `MobileNet_V2_Weights`       | Enum         | Pretrained weights for MobileNetV2       |
| `MobileNet_V3_Large_Weights` | Enum         | Pretrained weights for MobileNetV3-Large |
| `MobileNet_V3_Small_Weights` | Enum         | Pretrained weights for MobileNetV3-Small |

Understanding the variant (RegNet)(Regular Network)
| Name                      | Approx. FLOPs | Parameters | Description                     |
| ------------------------- | ------------- | ---------- | ------------------------------- |
| `400MF`                   | ~400 million | ~5M       | Very small                      |
| `800MF`                   | ~800 million | ~7M       | Lightweight                     |
| `1_6GF`                   | ~1.6 GFLOPs  | ~9M       | Mid-sized                       |
| `3_2GF`                   | ~3.2 GFLOPs  | ~15M      | Balanced model                  |
| `8GF`                     | ~8 GFLOPs    | ~39M      | Large                           |
| `16GF`                    | ~16 GFLOPs   | ~84M      | Very large                      |
| `32GF`                    | ~32 GFLOPs   | ~145M     | Very deep                       |
| `128GF` (only in RegNetY) | ~128 GFLOPs  | ~320M     | Extremely large, heavy-duty use |
 
 Difference between (RegNet X and Y)
 | Feature                     | RegNetX        | RegNetY          |
| --------------------------- | -------------- | ---------------- |
| SE (Squeeze-and-Excitation) | ‚ùå No           | ‚úÖ Yes            |
| Attention mechanism         | ‚ùå No           | ‚úÖ Yes            |
| Accuracy                    | Slightly lower | Better           |
| Speed                       | Faster         | Slightly slower  |
| Use Case                    | General        | Accuracy-focused |

Summary Table(RegNet)
| Variant                  | Family | Size            | Description                    |
| ------------------------ | ------ | --------------- | ------------------------------ |
| `RegNet_X_400MF_Weights` | X      | Small           | Efficient and fast             |
| `RegNet_X_800MF_Weights` | X      | Small           | Better than 400MF              |
| `RegNet_X_1_6GF_Weights` | X      | Medium          | Balanced                       |
| `RegNet_X_3_2GF_Weights` | X      | Medium          | Strong performance             |
| `RegNet_X_8GF_Weights`   | X      | Large           | Good accuracy                  |
| `RegNet_X_16GF_Weights`  | X      | Large           | High compute                   |
| `RegNet_X_32GF_Weights`  | X      | Very large      | Heavy workloads                |
| `RegNet_Y_400MF_Weights` | Y      | Small           | With attention (SE)            |
| `RegNet_Y_800MF_Weights` | Y      | Small           | Slightly better                |
| `RegNet_Y_1_6GF_Weights` | Y      | Medium          | Balanced with SE               |
| `RegNet_Y_3_2GF_Weights` | Y      | Medium          | Accuracy-focused               |
| `RegNet_Y_8GF_Weights`   | Y      | Large           | High performance               |
| `RegNet_Y_16GF_Weights`  | Y      | Very large      | Demands GPU                    |
| `RegNet_Y_32GF_Weights`  | Y      | Extra large     | High-end inference             |
| `RegNet_Y_128GF_Weights` | Y      | Extremely large | Rarely used unless in research |

Difference between Variant(ResNet)(Residual Network)
| Name                       | Architecture | Layers | Groups √ó Width | Parameters | Accuracy (ImageNet) | Description          |
| -------------------------- | ------------ | ------ | -------------- | ---------- | ------------------- | -------------------- |
| `ResNet18_Weights`         | ResNet       | 18     | -              | ~11M      | ~69.8%             | Lightweight          |
| `ResNet34_Weights`         | ResNet       | 34     | -              | ~21M      | ~73.3%             | Deeper               |
| `ResNet50_Weights`         | ResNet       | 50     | -              | ~25M      | ~76.2%             | Most commonly used   |
| `ResNet101_Weights`        | ResNet       | 101    | -              | ~44M      | ~77.4%             | More accurate        |
| `ResNet152_Weights`        | ResNet       | 152    | -              | ~60M      | ~78.3%             | Very deep            |
| `ResNeXt50_32X4D_Weights`  | ResNeXt      | 50     | 32√ó4           | ~25M      | ~77.6%             | Better than ResNet50 |
| `ResNeXt101_32X8D_Weights` | ResNeXt      | 101    | 32√ó8           | ~88M      | ~79.3%             |   Very powerful
|ResNeXt101_64X4D_Weights    | ResNeXt	    | 101     |64√ó4	      | ~83M	   |~79.6%	         |Wider version         |

Summary Table(ResNet)
| Model Enum                 | Base Architecture | Special Feature                      |
| -------------------------- | ----------------- | ------------------------------------ |
| `ResNet18_Weights`         | ResNet            | Lightest (shallow)                   |
| `ResNet34_Weights`         | ResNet            | Slightly deeper                      |
| `ResNet50_Weights`         | ResNet            | Balanced                             |
| `ResNet101_Weights`        | ResNet            | Deep                                 |
| `ResNet152_Weights`        | ResNet            | Very deep                            |
| `ResNeXt50_32X4D_Weights`  | ResNeXt           | Wider paths (32 groups √ó 4 channels) |
| `ResNeXt101_32X8D_Weights` | ResNeXt           | Deeper + wider                       |
| `ResNeXt101_64X4D_Weights` | ResNeXt           | Same depth, more groups              |

Variant Comparison (ShuffleNet)
| Variant | Width Multiplier | Parameters | ImageNet Top-1 Accuracy | Speed       | Use Case                           |
| ------- | ---------------- | ---------- | ----------------------- | ----------- | ---------------------------------- |
| `X0_5`  | 0.5√ó             | ~1.4M     | ~60.3%                 | ‚ö° Fastest   | Extremely resource-limited devices |
| `X1_0`  | 1.0√ó             | ~2.3M     | ~69.4%                 | ‚ö°‚ö° Fast     | Balanced choice                    |
| `X1_5`  | 1.5√ó             | ~3.5M     | ~72.6%                 | ‚ö°‚ö° Moderate | Better accuracy, still light       |
| `X2_0`  | 2.0√ó             | ~7.4M     | ~74.9%                 | ‚ö° Heavier   | Best accuracy among ShuffleNetV2   |

Summary Table(ShuffleNet)
| Term                         | Type               | Description                            |
| ---------------------------- | ------------------ | -------------------------------------- |
| `ShuffleNetV2`               | Model family       | Lightweight CNN with channel shuffling |
| `ShuffleNet_V2_X0_5_Weights` | Pretrained weights | Very small model (0.5√ó width)          |
| `ShuffleNet_V2_X1_0_Weights` | Pretrained weights | Default (1.0√ó width)                   |
| `ShuffleNet_V2_X1_5_Weights` | Pretrained weights | Wider (1.5√ó)                           |
| `ShuffleNet_V2_X2_0_Weights` | Pretrained weights | Widest (2.0√ó) and most accurate        |


Difference between SequeezeNet0 and 1
| Variant                 | Model          | Parameters | Accuracy (Top-1, ImageNet) | Input Size | Description             |
| ----------------------- | -------------- | ---------- | -------------------------- | ---------- | ----------------------- |
| `SqueezeNet1_0_Weights` | SqueezeNet 1.0 | ~1.25M    | ~57.5%                    | 227√ó227    | Original model          |
| `SqueezeNet1_1_Weights` | SqueezeNet 1.1 | ~1.24M    | ~58.2%                    | 224√ó224    | Smaller, faster version |

Key Difference
| Aspect       | `1.0`           | `1.1`                         |
| ------------ | --------------- | ----------------------------- |
| Accuracy     | Slightly lower  | Slightly better               |
| Speed        | Slower          | Faster                        |
| Input size   | 227√ó227         | 224√ó224                       |
| Architecture | Original design | Tweaked for better efficiency |

Summary Table 
| Term                    | Type               | Description                                    |
| ----------------------- | ------------------ | ---------------------------------------------- |
| `SqueezeNet`            | Model family       | Tiny CNN using Fire modules                    |
| `SqueezeNet1_0_Weights` | Pretrained weights | Original version (\~227x227 input)             |
| `SqueezeNet1_1_Weights` | Pretrained weights | Faster, slightly more accurate (224x224 input) |

Understanding the Variant(Swim)
| Name        | Meaning    | Parameters | Top-1 Accuracy (ImageNet) |
| ----------- | ---------- | ---------- | ------------------------- |
| `Swin_T`    | Tiny       | ~29M      | ~81.2%                   |
| `Swin_S`    | Small      | ~50M      | ~83.2%                   |
| `Swin_B`    | Base       | ~88M      | ~83.5%                   |
| `Swin_V2_T` | Tiny (v2)  | ~28M      | ~83.1%                   |
| `Swin_V2_S` | Small (v2) | ~49M      | ~84.5%                   |
| `Swin_V2_B` | Base (v2)  | ~88M      | ~84.6%                   |

Summary Table(swim)
| Model               | Type               | Description                                                 |
| ------------------- | ------------------ | ----------------------------------------------------------- |
| `SwinTransformer`   | Architecture       | Vision Transformer with shifted windows                     |
| `Swin_T_Weights`    | Pretrained weights | Tiny variant of Swin V1                                     |
| `Swin_S_Weights`    | Pretrained weights | Small variant of Swin V1                                    |
| `Swin_B_Weights`    | Pretrained weights | Base variant of Swin V1                                     |
| `Swin_V2_T_Weights` | Pretrained weights | Tiny variant of Swin V2 (more accurate)                     |
| `Swin_V2_S_Weights` | Pretrained weights | Small variant of Swin V2                                    |
| `Swin_V2_B_Weights` | Pretrained weights | Base variant of Swin V2 (best balance of size and accuracy) |



Summary Table (VGG)(Visual Geometry Group)
| Name               | Architecture | BN | Parameters | Accuracy | Description                  |
| ------------------ | ------------ | -- | ---------- | -------- | ---------------------------- |
| `VGG11_Weights`    | VGG11        | ‚ùå  | ~132M     | ~69.0%  | Simplest version             |
| `VGG11_BN_Weights` | VGG11        | ‚úÖ  | ~132M     | ~70.4%  | With BatchNorm               |
| `VGG13_Weights`    | VGG13        | ‚ùå  | ~133M     | ~69.9%  | Slightly deeper              |
| `VGG13_BN_Weights` | VGG13        | ‚úÖ  | ~133M     | ~71.6%  | Better accuracy              |
| `VGG16_Weights`    | VGG16        | ‚ùå  | ~138M     | ~71.5%  | Classic, no BN               |
| `VGG16_BN_Weights` | VGG16        | ‚úÖ  | ~138M     | ~73.4%  | Most used                    |
| `VGG19_Weights`    | VGG19        | ‚ùå  | ~144M     | ~71.8%  | Deepest version              |
| `VGG19_BN_Weights` | VGG19        | ‚úÖ  | ~144M     | ~74.2%  | Best accuracy among all VGGs |

Model Comparison Table(Vit)(Vision Transformer)
| Model              | Size  | Patch | Params | Input Size | Accuracy (ImageNet) |
| ------------------ | ----- | ----- | ------ | ---------- | ------------------- |
| `ViT_B_16_Weights` | Base  | 16√ó16 | ~86M  | 224√ó224    | ~81.1%             |
| `ViT_B_32_Weights` | Base  | 32√ó32 | ~88M  | 224√ó224    | ~77.9%             |
| `ViT_L_16_Weights` | Large | 16√ó16 | ~307M | 224√ó224    | ~82.5%             |
| `ViT_L_32_Weights` | Large | 32√ó32 | ~305M | 224√ó224    | ~79.9%             |
| `ViT_H_14_Weights` | Huge  | 14√ó14 | ~632M | 518√ó518    | ~85.1%             |

Summary Table(Vit)
| Name               | Transformer Size | Patch Size | Notes                                                 |
| ------------------ | ---------------- | ---------- | ----------------------------------------------------- |
| `ViT_B_16_Weights` | Base             | 16√ó16      | Best balance (default choice)                         |
| `ViT_B_32_Weights` | Base             | 32√ó32      | Faster, less accurate                                 |
| `ViT_L_16_Weights` | Large            | 16√ó16      | More accurate, heavier                                |
| `ViT_L_32_Weights` | Large            | 32√ó32      | Tradeoff: less accurate than L-16                     |
| `ViT_H_14_Weights` | Huge             | 14√ó14      | State-of-the-art accuracy, huge model (needs big GPU) |


